# 🗓️ 2025.08.01(금) – 교육 일지

## 📚 오늘 배운 내용
### LLM
#### TTS(Text-to-Speech)
- TTS란?
  - 텍스트를 음성으로 변환시켜주는 기술
  - 글로 된 문장을 AI 모델이 사람처럼 자연스럽게 읽어주는 기술
- GPT 음성 종류
  - Alloy: 부드럽고 자연스러운 톤의 음성.
  - Echo: 명확하고 자신감있는 음성.
  - Fable: 이야기 전달에 적합한 서정적인 음성.
  - Onyx: 전문적이고 신뢰감을 주는 음성.
  - Nova: 활기차고 에너지 넘치는 음성.
  - Shimmer: 부드럽고 진정시키는 음성.
- 예시
  ```
  from openai import OpenAI

  client = OpenAI()
  
  text = "안녕하세요. 오늘 날씨가 참 좋네요."
  
  with client.audio.speech.with_streaming_response.create(
    model="tts-1",
    voice="alloy",
    input=text
  ) as response:
    response.stream_to_file("output.mp3")
  ```
- 주요 파라미터

  | 파라미터               | 설명                                                  |
  | ------------------ | --------------------------------------------------- |
  | `model`            | 사용할 TTS 모델 (`tts-1` / `tts-1-hd` 등)                 |
  | `voice`            | 출력 음성 스타일 (alloy, echo, fable, onyx, nova, shimmer) |
  | `input`            | 변환할 텍스트 문자열                                         |
  | `stream_to_file()` | 변환된 오디오를 지정된 파일로 저장                                 |

#### STT
- STT란?
  - 사람이 말한 음성을 AI가 분석해서 글로 변환해주는 기술
- 예시
  ```
  from openai import OpenAI

  client = OpenAI()
  
  with open("output.mp3", "rb") as f:
    transcription = client.audio.transcriptions.create(
      model="whisper-1",  # STT 모델
      file=f              # 변환할 오디오 파일
    )
  print(transcription.text)
  ```
- 주요 파라미터

  | 파라미터              | 설명                                            |
  | ----------------- | --------------------------------------------- |
  | `model`           | 사용 모델 이름 (`whisper-1`)                        |
  | `file`            | 변환할 음성 파일 (mp3, wav, m4a, webm 등)             |
  | `language` *(선택)* | 음성 언어를 지정하면 인식률 향상 (`"ko"`, `"en"`, `"ja"` 등) |
- Whisper STT 특징
  - 멀티랭귀지 지원 → 한국어, 영어, 일본어 등 대부분의 언어 인식 가능
  - 자동 언어 감지 → language를 지정하지 않아도 자동으로 언어 감지
  - 고품질 변환 → 잡음 속 대화도 비교적 잘 인식
  - 파일 크기 제한 → API로는 일반적으로 수 분 길이 오디오를 처리 (긴 경우 쪼개서 처리)
  
#### embeddings
- 임베딩이란?
  - 텍스트(또는 이미지, 오디오 등)를 고정 길이의 숫자 벡터로 변환한 것
  - 이 숫자 벡터는 의미(semantic meaning) 를 반영하도록 학습됨
  - 벡터 공간에서 비슷한 의미의 데이터는 가까이, 다른 의미는 멀리 위치함
- 임베딩의 활용
  - 검색(Search)
    - 질문을 임베딩으로 변환 → DB 내 문서 임베딩과 비교 → 가장 가까운 문서 반환
    - 예: ChatGPT의 RAG(Retrieval-Augmented Generation)
  - 군집화(Clustering)
    - 비슷한 의미의 문서끼리 자동으로 묶음
  - 추천 시스템(Recommendation)
    - 유저가 좋아한 아이템 임베딩과 유사한 아이템 추천
  - 이상 탐지(Anomaly Detection)
    - 벡터 거리가 평소보다 크면 이상치로 판단
  - 분류(Classification)
    - 벡터를 머신러닝 모델 입력으로 사용하여 분류 수행
- 임베딩의 거리 측정
  - 임베딩 벡터 간 유사도는 코사인 유사도(cosine similarity) 또는 유클리드 거리로 측정
  - 두 벡터 간 거리(코사인 유사도)가 0.9 이상이면 의미가 매우 비슷하다고 판단
  - 예시:
    - cosine_similarity = 1 → 의미가 완전히 같음
    - cosine_similarity = 0 → 전혀 관련 없음 
- Open AI 임베딩 모델

  | 모델                       | 차원 수(Dimensions) | 특징             |
  | ------------------------ | ---------------- | -------------- |
  | `text-embedding-3-small` | 1536             | 속도 빠름, 저비용     |
  | `text-embedding-3-large` | 3072             | 더 높은 정밀도, 비용 ↑ |

#### moderation
- moderation이란?
  - 사용자가 입력한 텍스트, 이미지, 오디오 등의 콘텐츠가 안전한지 자동으로 판단하는 기능
  - OpenAI의 Moderation API는 폭력, 혐오, 성적 콘텐츠, 자기해, 불법 활동 등 정책 위반 가능성을 감지함
- moderation의 주요 목적
  - 서비스 안전성 확보
    - AI 챗봇, 검색, 커뮤니티 서비스에서 부적절한 콘텐츠를 사전에 차단
  - 법률 및 규제 준수
    - 특정 국가에서 불법이거나 규제되는 발언 방지
  - 브랜드 신뢰성 유지
    - 기업 서비스에서 부적절한 표현 유입 방지
- 예시
  ```
  from openai import OpenAI
  import pandas as pd
  
  client = OpenAI()
  
  response = client.moderations.create(
    model="omni-moderation-latest",
    input="R U CRAZY?? What the FUCK. SHUT UP!!"
  )
  
  moderation_df = pd.DataFrame(response.results[0].categories, columns=['category', 'bool'])
  moderation_df
  ```
- 주요 카테고리 예시
  - sexual : 성적 콘텐츠
  - violence : 폭력적인 내용
  - self-harm : 자해, 자살 관련
  - hate : 혐오 발언
  - harassment : 괴롭힘, 모욕
  - illegal : 불법 활동
  - 그 외에도 세부 카테고리 존재 (예: 성착취, 아동 착취 등)
  
## ✍️ 오늘의 회고
- tts와 stt를 손쉽게 만들 수 있어서 놀랐다.
- 챗봇 만들 떄 moderation 관련된 것은 꼭 넣어야겠다.